{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29db6cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 12:33:47.856170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdad42d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 5500M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 12:33:51.639367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 12:33:51.640127: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-25 12:33:51.640174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 12:33:51.640491: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc6/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " fc7/relu (Activation)       (None, 4096)              0         \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 2622)              10742334  \n",
      "                                                                 \n",
      " fc8/softmax (Activation)    (None, 2622)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a vggface model\n",
    "model = VGGFace(model='vgg16')\n",
    "model.summary()\n",
    "# model = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933d17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "Outputs: [<KerasTensor: shape=(None, 2622) dtype=float32 (created by layer 'fc8')>]\n"
     ]
    }
   ],
   "source": [
    "# summarize input and output shape\n",
    "layer_name = 'fc8'\n",
    "out = model.get_layer(layer_name).output\n",
    "model = Model(model.input, out)\n",
    "print('Inputs: %s' % model.inputs)\n",
    "print('Outputs: %s' % model.outputs)\n",
    "target_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b255834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '/Users/santhoshnarayanan/Documents/Turing/GPU/VGGData/testset'\n",
    "celebs  = []\n",
    " \n",
    "for r, d, f in os.walk(db_path): # r=root, d=directories, f = files\n",
    "    for file in f:\n",
    "        if ('.jpg' in file):\n",
    "            exact_path = r + \"/\" + file\n",
    "            celebs.append(exact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021b5abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 224, 224, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = [image.load_img(img, target_size=target_shape) for img in celebs]\n",
    "X = np.float32([utils.preprocess_input(np.float32(img), version=1) for img in imgs])\n",
    "display(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4db4747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 79s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4000, 2622)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repA = model.predict(X[0:4000], batch_size=64)\n",
    "display(repA.shape)\n",
    "repB = model.predict(X[4000:8000], batch_size=64)\n",
    "display(repB.shape)\n",
    "rep = np.concatenate((repA, repB), axis=0)\n",
    "display(rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf9a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celeb</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2612</th>\n",
       "      <th>2613</th>\n",
       "      <th>2614</th>\n",
       "      <th>2615</th>\n",
       "      <th>2616</th>\n",
       "      <th>2617</th>\n",
       "      <th>2618</th>\n",
       "      <th>2619</th>\n",
       "      <th>2620</th>\n",
       "      <th>2621</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>2.594817</td>\n",
       "      <td>-0.434783</td>\n",
       "      <td>0.606621</td>\n",
       "      <td>3.266035</td>\n",
       "      <td>0.597103</td>\n",
       "      <td>0.600513</td>\n",
       "      <td>0.553012</td>\n",
       "      <td>1.848994</td>\n",
       "      <td>1.382500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240451</td>\n",
       "      <td>-2.922260</td>\n",
       "      <td>-2.544503</td>\n",
       "      <td>-0.245354</td>\n",
       "      <td>-1.331547</td>\n",
       "      <td>-2.866831</td>\n",
       "      <td>-3.229215</td>\n",
       "      <td>1.122466</td>\n",
       "      <td>0.182207</td>\n",
       "      <td>-0.755669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>4.750790</td>\n",
       "      <td>5.448501</td>\n",
       "      <td>3.474746</td>\n",
       "      <td>0.601897</td>\n",
       "      <td>-0.498479</td>\n",
       "      <td>4.499108</td>\n",
       "      <td>2.579011</td>\n",
       "      <td>3.014450</td>\n",
       "      <td>2.216500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.711684</td>\n",
       "      <td>0.259915</td>\n",
       "      <td>-2.627894</td>\n",
       "      <td>2.191211</td>\n",
       "      <td>-2.450251</td>\n",
       "      <td>-1.941559</td>\n",
       "      <td>-4.495428</td>\n",
       "      <td>-1.467024</td>\n",
       "      <td>1.814163</td>\n",
       "      <td>4.478118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>-1.341132</td>\n",
       "      <td>-0.609385</td>\n",
       "      <td>-2.179606</td>\n",
       "      <td>-1.865505</td>\n",
       "      <td>0.425404</td>\n",
       "      <td>-0.199042</td>\n",
       "      <td>-0.385628</td>\n",
       "      <td>1.690739</td>\n",
       "      <td>2.659145</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.399040</td>\n",
       "      <td>0.780722</td>\n",
       "      <td>-2.663496</td>\n",
       "      <td>3.260226</td>\n",
       "      <td>1.200716</td>\n",
       "      <td>2.132750</td>\n",
       "      <td>1.412410</td>\n",
       "      <td>-4.562939</td>\n",
       "      <td>1.582824</td>\n",
       "      <td>4.562842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>4.770988</td>\n",
       "      <td>-0.243045</td>\n",
       "      <td>2.897161</td>\n",
       "      <td>3.664442</td>\n",
       "      <td>2.233140</td>\n",
       "      <td>1.924740</td>\n",
       "      <td>0.763086</td>\n",
       "      <td>1.576417</td>\n",
       "      <td>2.291085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259052</td>\n",
       "      <td>-1.911187</td>\n",
       "      <td>-2.592706</td>\n",
       "      <td>-1.359860</td>\n",
       "      <td>1.776673</td>\n",
       "      <td>-0.531952</td>\n",
       "      <td>-1.619988</td>\n",
       "      <td>-4.511042</td>\n",
       "      <td>-0.369517</td>\n",
       "      <td>0.393388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>4.272125</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>-1.333247</td>\n",
       "      <td>1.142551</td>\n",
       "      <td>1.687836</td>\n",
       "      <td>0.479853</td>\n",
       "      <td>1.028407</td>\n",
       "      <td>4.002062</td>\n",
       "      <td>2.825842</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489381</td>\n",
       "      <td>-1.539137</td>\n",
       "      <td>-1.731887</td>\n",
       "      <td>-1.743123</td>\n",
       "      <td>-1.382905</td>\n",
       "      <td>-2.189632</td>\n",
       "      <td>-2.511028</td>\n",
       "      <td>0.873662</td>\n",
       "      <td>1.694410</td>\n",
       "      <td>0.746357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>-1.207366</td>\n",
       "      <td>2.731673</td>\n",
       "      <td>-3.874018</td>\n",
       "      <td>-1.336324</td>\n",
       "      <td>-3.074984</td>\n",
       "      <td>-1.517171</td>\n",
       "      <td>2.307636</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>3.631700</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.840803</td>\n",
       "      <td>3.292569</td>\n",
       "      <td>2.218327</td>\n",
       "      <td>3.362937</td>\n",
       "      <td>2.148040</td>\n",
       "      <td>0.198981</td>\n",
       "      <td>-2.201727</td>\n",
       "      <td>-2.777040</td>\n",
       "      <td>8.273804</td>\n",
       "      <td>6.484615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>8.765278</td>\n",
       "      <td>10.337363</td>\n",
       "      <td>9.235224</td>\n",
       "      <td>1.467477</td>\n",
       "      <td>6.949498</td>\n",
       "      <td>3.644549</td>\n",
       "      <td>4.231451</td>\n",
       "      <td>7.804096</td>\n",
       "      <td>3.244748</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.637619</td>\n",
       "      <td>-3.443918</td>\n",
       "      <td>-4.422450</td>\n",
       "      <td>-1.388282</td>\n",
       "      <td>0.481939</td>\n",
       "      <td>-5.317516</td>\n",
       "      <td>-4.708521</td>\n",
       "      <td>-5.240987</td>\n",
       "      <td>-3.128758</td>\n",
       "      <td>4.211435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>1.069455</td>\n",
       "      <td>-0.432792</td>\n",
       "      <td>1.427405</td>\n",
       "      <td>2.181358</td>\n",
       "      <td>0.294008</td>\n",
       "      <td>3.443064</td>\n",
       "      <td>1.722770</td>\n",
       "      <td>4.330018</td>\n",
       "      <td>-0.317990</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.676923</td>\n",
       "      <td>-4.648773</td>\n",
       "      <td>-1.593403</td>\n",
       "      <td>0.832667</td>\n",
       "      <td>1.776019</td>\n",
       "      <td>1.521085</td>\n",
       "      <td>1.532222</td>\n",
       "      <td>2.159128</td>\n",
       "      <td>3.509219</td>\n",
       "      <td>4.177240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>0.156092</td>\n",
       "      <td>0.584193</td>\n",
       "      <td>0.379440</td>\n",
       "      <td>-1.961920</td>\n",
       "      <td>1.778721</td>\n",
       "      <td>1.374092</td>\n",
       "      <td>3.356516</td>\n",
       "      <td>1.222736</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.187177</td>\n",
       "      <td>-0.175232</td>\n",
       "      <td>-4.768421</td>\n",
       "      <td>0.925566</td>\n",
       "      <td>2.913509</td>\n",
       "      <td>8.612916</td>\n",
       "      <td>-2.260141</td>\n",
       "      <td>-1.507633</td>\n",
       "      <td>2.332282</td>\n",
       "      <td>4.463278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>/Users/santhoshnarayanan/Documents/Turing/GPU/...</td>\n",
       "      <td>3.440565</td>\n",
       "      <td>0.966827</td>\n",
       "      <td>0.416298</td>\n",
       "      <td>-1.383956</td>\n",
       "      <td>1.126038</td>\n",
       "      <td>1.246027</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>4.580691</td>\n",
       "      <td>0.502470</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.209802</td>\n",
       "      <td>0.588104</td>\n",
       "      <td>-0.018851</td>\n",
       "      <td>0.410286</td>\n",
       "      <td>1.477676</td>\n",
       "      <td>-3.122083</td>\n",
       "      <td>2.319118</td>\n",
       "      <td>0.432402</td>\n",
       "      <td>1.405047</td>\n",
       "      <td>6.008420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 2623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  celeb         0          1  \\\n",
       "0     /Users/santhoshnarayanan/Documents/Turing/GPU/...  2.594817  -0.434783   \n",
       "1     /Users/santhoshnarayanan/Documents/Turing/GPU/...  4.750790   5.448501   \n",
       "2     /Users/santhoshnarayanan/Documents/Turing/GPU/... -1.341132  -0.609385   \n",
       "3     /Users/santhoshnarayanan/Documents/Turing/GPU/...  4.770988  -0.243045   \n",
       "4     /Users/santhoshnarayanan/Documents/Turing/GPU/...  4.272125  -0.029436   \n",
       "...                                                 ...       ...        ...   \n",
       "7995  /Users/santhoshnarayanan/Documents/Turing/GPU/... -1.207366   2.731673   \n",
       "7996  /Users/santhoshnarayanan/Documents/Turing/GPU/...  8.765278  10.337363   \n",
       "7997  /Users/santhoshnarayanan/Documents/Turing/GPU/...  1.069455  -0.432792   \n",
       "7998  /Users/santhoshnarayanan/Documents/Turing/GPU/... -0.113445   0.156092   \n",
       "7999  /Users/santhoshnarayanan/Documents/Turing/GPU/...  3.440565   0.966827   \n",
       "\n",
       "             2         3         4         5         6         7         8  \\\n",
       "0     0.606621  3.266035  0.597103  0.600513  0.553012  1.848994  1.382500   \n",
       "1     3.474746  0.601897 -0.498479  4.499108  2.579011  3.014450  2.216500   \n",
       "2    -2.179606 -1.865505  0.425404 -0.199042 -0.385628  1.690739  2.659145   \n",
       "3     2.897161  3.664442  2.233140  1.924740  0.763086  1.576417  2.291085   \n",
       "4    -1.333247  1.142551  1.687836  0.479853  1.028407  4.002062  2.825842   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995 -3.874018 -1.336324 -3.074984 -1.517171  2.307636  0.762435  3.631700   \n",
       "7996  9.235224  1.467477  6.949498  3.644549  4.231451  7.804096  3.244748   \n",
       "7997  1.427405  2.181358  0.294008  3.443064  1.722770  4.330018 -0.317990   \n",
       "7998  0.584193  0.379440 -1.961920  1.778721  1.374092  3.356516  1.222736   \n",
       "7999  0.416298 -1.383956  1.126038  1.246027  0.695378  4.580691  0.502470   \n",
       "\n",
       "      ...      2612      2613      2614      2615      2616      2617  \\\n",
       "0     ...  0.240451 -2.922260 -2.544503 -0.245354 -1.331547 -2.866831   \n",
       "1     ... -0.711684  0.259915 -2.627894  2.191211 -2.450251 -1.941559   \n",
       "2     ... -2.399040  0.780722 -2.663496  3.260226  1.200716  2.132750   \n",
       "3     ... -0.259052 -1.911187 -2.592706 -1.359860  1.776673 -0.531952   \n",
       "4     ... -1.489381 -1.539137 -1.731887 -1.743123 -1.382905 -2.189632   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  ... -2.840803  3.292569  2.218327  3.362937  2.148040  0.198981   \n",
       "7996  ... -2.637619 -3.443918 -4.422450 -1.388282  0.481939 -5.317516   \n",
       "7997  ... -2.676923 -4.648773 -1.593403  0.832667  1.776019  1.521085   \n",
       "7998  ... -3.187177 -0.175232 -4.768421  0.925566  2.913509  8.612916   \n",
       "7999  ... -2.209802  0.588104 -0.018851  0.410286  1.477676 -3.122083   \n",
       "\n",
       "          2618      2619      2620      2621  \n",
       "0    -3.229215  1.122466  0.182207 -0.755669  \n",
       "1    -4.495428 -1.467024  1.814163  4.478118  \n",
       "2     1.412410 -4.562939  1.582824  4.562842  \n",
       "3    -1.619988 -4.511042 -0.369517  0.393388  \n",
       "4    -2.511028  0.873662  1.694410  0.746357  \n",
       "...        ...       ...       ...       ...  \n",
       "7995 -2.201727 -2.777040  8.273804  6.484615  \n",
       "7996 -4.708521 -5.240987 -3.128758  4.211435  \n",
       "7997  1.532222  2.159128  3.509219  4.177240  \n",
       "7998 -2.260141 -1.507633  2.332282  4.463278  \n",
       "7999  2.319118  0.432402  1.405047  6.008420  \n",
       "\n",
       "[8000 rows x 2623 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(rep)  \n",
    "df.insert(loc = 0,\n",
    "          column = 'celeb',\n",
    "          value = celebs)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ef106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rep_VGG16.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
